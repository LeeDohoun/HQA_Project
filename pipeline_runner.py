#!/usr/bin/env python
# -*- coding: utf-8 -*-
# íŒŒì¼: pipeline_runner.py
"""
HQA ë°ì´í„° ìˆ˜ì§‘/ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ CLI ì‹¤í–‰ê¸°

ì‚¬ìš©ë²•:
    # íŠ¹ì • ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ + ì¸ë±ì‹±
    python pipeline_runner.py ingest --code 005930 --name ì‚¼ì„±ì „ì
    
    # ì—¬ëŸ¬ ì¢…ëª© ì¼ê´„ ìˆ˜ì§‘
    python pipeline_runner.py ingest-batch --codes 005930,000660,035420
    
    # PDF íŒŒì¼/ë””ë ‰í† ë¦¬ ì§ì ‘ ì¸ë±ì‹±
    python pipeline_runner.py index-pdf --path ./data/reports/example.pdf
    python pipeline_runner.py index-dir --path ./data/reports --pattern "*.pdf"
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    python pipeline_runner.py search --query "ì‚¼ì„±ì „ì ì‹¤ì "
    
    # ìƒíƒœ í™•ì¸
    python pipeline_runner.py status
    
    # ì„ë² ë”© ì¬êµ¬ì¶•
    python pipeline_runner.py rebuild --code 005930
"""

import argparse
import sys
import os
from typing import List, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def get_pipeline():
    """íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    from src.data_pipeline import DataIngestionPipeline
    return DataIngestionPipeline(
        db_path="./database/raw_data.db",
        files_dir="./data/files",
        vector_persist_dir="./database/chroma_db",
        collection_name="stock_data",
        use_reranker=True,
        retrieval_k=20,
        rerank_top_k=3
    )


# ==================== ì¢…ëª© ì½”ë“œ ë§¤í•‘ ====================

STOCK_CODES = {
    # ëŒ€í˜•ì£¼
    "005930": "ì‚¼ì„±ì „ì",
    "000660": "SKí•˜ì´ë‹‰ìŠ¤",
    "035420": "NAVER",
    "035720": "ì¹´ì¹´ì˜¤",
    "051910": "LGí™”í•™",
    "006400": "ì‚¼ì„±SDI",
    "207940": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤",
    "005380": "í˜„ëŒ€ì°¨",
    "000270": "ê¸°ì•„",
    "068270": "ì…€íŠ¸ë¦¬ì˜¨",
    "028260": "ì‚¼ì„±ë¬¼ì‚°",
    "105560": "KBê¸ˆìœµ",
    "055550": "ì‹ í•œì§€ì£¼",
    "086790": "í•˜ë‚˜ê¸ˆìœµì§€ì£¼",
    "066570": "LGì „ì",
    "096770": "SKì´ë…¸ë² ì´ì…˜",
    "034730": "SK",
    "015760": "í•œêµ­ì „ë ¥",
    "003670": "í¬ìŠ¤ì½”í™€ë”©ìŠ¤",
    "033780": "KT&G",
}


def get_stock_name(code: str) -> str:
    """ì¢…ëª©ì½”ë“œë¡œ ì¢…ëª©ëª… ì¡°íšŒ"""
    return STOCK_CODES.get(code, f"ì¢…ëª©{code}")


# ==================== CLI ì»¤ë§¨ë“œ ====================

def cmd_ingest(args):
    """íŠ¹ì • ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ + ì¸ë±ì‹±"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ ë°ì´í„° ìˆ˜ì§‘/ì¸ë±ì‹± ì‹œì‘")
    print(f"   ì¢…ëª©: {args.name} ({args.code})")
    print(f"{'='*60}")
    
    pipeline = get_pipeline()
    
    results = pipeline.ingest_stock_data(
        stock_code=args.code,
        stock_name=args.name,
        include_reports=not args.no_reports,
        include_news=not args.no_news,
        include_dart=not args.no_dart,
        include_price=not args.no_price,
        auto_embed=not args.no_embed
    )
    
    return results


def cmd_ingest_batch(args):
    """ì—¬ëŸ¬ ì¢…ëª© ì¼ê´„ ìˆ˜ì§‘"""
    codes = args.codes.split(",")
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ ì¼ê´„ ìˆ˜ì§‘ ì‹œì‘ ({len(codes)}ê°œ ì¢…ëª©)")
    print(f"{'='*60}")
    
    pipeline = get_pipeline()
    all_results = []
    
    for code in codes:
        code = code.strip()
        name = get_stock_name(code)
        
        print(f"\nğŸ“Š [{name}({code})] ì²˜ë¦¬ ì¤‘...")
        
        try:
            results = pipeline.ingest_stock_data(
                stock_code=code,
                stock_name=name,
                include_reports=True,
                include_news=True,
                include_dart=True,
                include_price=True,
                auto_embed=True
            )
            all_results.append(results)
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    # ìš”ì•½
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ì¼ê´„ ìˆ˜ì§‘ ì™„ë£Œ")
    print(f"{'='*60}")
    
    for result in all_results:
        print(f"   - {result['stock_name']}: "
              f"ìˆ˜ì§‘ {result['collected']['reports']+result['collected']['news']+result['collected']['disclosures']}ê±´, "
              f"ì„ë² ë”© {result['embedded']['reports']+result['embedded']['news']+result['embedded']['disclosures']}ê±´")
    
    return all_results


def cmd_index_pdf(args):
    """PDF íŒŒì¼ ì§ì ‘ ì¸ë±ì‹±"""
    print(f"\nğŸ“„ PDF ì¸ë±ì‹±: {args.path}")
    
    if not os.path.exists(args.path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.path}")
        return None
    
    pipeline = get_pipeline()
    
    metadata = {}
    if args.stock_code:
        metadata["stock_code"] = args.stock_code
    if args.stock_name:
        metadata["stock_name"] = args.stock_name
    if args.data_type:
        metadata["data_type"] = args.data_type
    
    result = pipeline.index_pdf(
        file_path=args.path,
        metadata=metadata if metadata else None
    )
    
    return result


def cmd_index_dir(args):
    """ë””ë ‰í† ë¦¬ ì¼ê´„ ì¸ë±ì‹±"""
    print(f"\nğŸ“ ë””ë ‰í† ë¦¬ ì¸ë±ì‹±: {args.path}")
    
    if not os.path.isdir(args.path):
        print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.path}")
        return None
    
    pipeline = get_pipeline()
    
    patterns = args.pattern.split(",") if args.pattern else ["*.pdf"]
    
    metadata = {}
    if args.stock_code:
        metadata["stock_code"] = args.stock_code
    if args.stock_name:
        metadata["stock_name"] = args.stock_name
    
    result = pipeline.index_directory(
        directory=args.path,
        file_patterns=patterns,
        metadata=metadata if metadata else None,
        recursive=not args.no_recursive
    )
    
    return result


def cmd_search(args):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ” ê²€ìƒ‰: '{args.query}'")
    
    pipeline = get_pipeline()
    
    docs = pipeline.search(
        query=args.query,
        k=args.k,
        use_reranker=not args.no_reranker
    )
    
    print(f"\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê±´")
    print("="*60)
    
    for i, doc in enumerate(docs, 1):
        print(f"\n[{i}] {doc.metadata.get('data_type', 'unknown').upper()}")
        print(f"    ì¢…ëª©: {doc.metadata.get('stock_name', 'N/A')}")
        print(f"    ì¶œì²˜: {doc.metadata.get('source', doc.metadata.get('source_url', 'N/A'))}")
        print(f"    ë‚´ìš©: {doc.page_content[:200]}...")
    
    return docs


def cmd_status(args):
    """ìƒíƒœ í™•ì¸"""
    print("\nğŸ“Š íŒŒì´í”„ë¼ì¸ ìƒíƒœ")
    print("="*60)
    
    pipeline = get_pipeline()
    stats = pipeline.get_stats()
    
    # ì›ë³¸ ë°ì´í„° ìƒíƒœ
    raw = stats.get("raw_data", {})
    print(f"\nğŸ’¾ ì›ë³¸ ë°ì´í„° (SQLite)")
    print(f"   - ë¦¬í¬íŠ¸: {raw.get('reports', 0)}ê±´")
    print(f"   - ë‰´ìŠ¤: {raw.get('news', 0)}ê±´")
    print(f"   - ê³µì‹œ: {raw.get('disclosures', 0)}ê±´")
    print(f"   - ì£¼ê°€: {raw.get('price', 0)}ê±´")
    print(f"   - DB í¬ê¸°: {raw.get('db_size_mb', 'N/A')}MB")
    
    # ë²¡í„° ì €ì¥ì†Œ ìƒíƒœ
    vector = stats.get("vector_store", {})
    print(f"\nğŸ§  ë²¡í„° ì €ì¥ì†Œ (ChromaDB)")
    print(f"   - ë¬¸ì„œ ìˆ˜: {vector.get('total_documents', 0)}ê±´")
    print(f"   - ì €ì¥ì†Œ í¬ê¸°: {vector.get('size_mb', 'N/A')}MB")
    
    return stats


def cmd_rebuild(args):
    """ì„ë² ë”© ì¬êµ¬ì¶•"""
    print(f"\nğŸ”„ ì„ë² ë”© ì¬êµ¬ì¶•")
    
    if args.code:
        print(f"   ëŒ€ìƒ: {args.code}")
    else:
        print(f"   ëŒ€ìƒ: ì „ì²´")
    
    confirm = input("\nâš ï¸ ì •ë§ ì¬êµ¬ì¶•í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if confirm.lower() != 'y':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None
    
    pipeline = get_pipeline()
    result = pipeline.rebuild_embeddings(stock_code=args.code)
    
    return result


def cmd_clear(args):
    """ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”"""
    print("\nâš ï¸ ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”")
    print("   ì´ ì‘ì—…ì€ ëª¨ë“  ì„ë² ë”©ì„ ì‚­ì œí•©ë‹ˆë‹¤!")
    
    confirm = input("\nì •ë§ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yesë¥¼ ì…ë ¥): ")
    if confirm != 'yes':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None
    
    pipeline = get_pipeline()
    pipeline.clear_vector_store()
    
    print("âœ… ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True


# ==================== ë©”ì¸ ====================

def main():
    parser = argparse.ArgumentParser(
        description="HQA ë°ì´í„° ìˆ˜ì§‘/ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì‚¼ì„±ì „ì ë°ì´í„° ìˆ˜ì§‘
  python pipeline_runner.py ingest --code 005930 --name ì‚¼ì„±ì „ì

  # ì—¬ëŸ¬ ì¢…ëª© ì¼ê´„ ìˆ˜ì§‘
  python pipeline_runner.py ingest-batch --codes 005930,000660,035420

  # PDF íŒŒì¼ ì¸ë±ì‹±
  python pipeline_runner.py index-pdf --path ./reports/sample.pdf

  # ê²€ìƒ‰
  python pipeline_runner.py search --query "ì‚¼ì„±ì „ì ë°˜ë„ì²´ ì‹¤ì "

  # ìƒíƒœ í™•ì¸
  python pipeline_runner.py status
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")
    
    # ingest ëª…ë ¹ì–´
    ingest_parser = subparsers.add_parser("ingest", help="íŠ¹ì • ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ + ì¸ë±ì‹±")
    ingest_parser.add_argument("--code", required=True, help="ì¢…ëª©ì½”ë“œ (ì˜ˆ: 005930)")
    ingest_parser.add_argument("--name", required=True, help="ì¢…ëª©ëª… (ì˜ˆ: ì‚¼ì„±ì „ì)")
    ingest_parser.add_argument("--no-reports", action="store_true", help="ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì œì™¸")
    ingest_parser.add_argument("--no-news", action="store_true", help="ë‰´ìŠ¤ ìˆ˜ì§‘ ì œì™¸")
    ingest_parser.add_argument("--no-dart", action="store_true", help="DART ê³µì‹œ ì œì™¸")
    ingest_parser.add_argument("--no-price", action="store_true", help="ì£¼ê°€ ë°ì´í„° ì œì™¸")
    ingest_parser.add_argument("--no-embed", action="store_true", help="ìë™ ì„ë² ë”© ì œì™¸")
    
    # ingest-batch ëª…ë ¹ì–´
    batch_parser = subparsers.add_parser("ingest-batch", help="ì—¬ëŸ¬ ì¢…ëª© ì¼ê´„ ìˆ˜ì§‘")
    batch_parser.add_argument("--codes", required=True, help="ì¢…ëª©ì½”ë“œ ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: 005930,000660)")
    
    # index-pdf ëª…ë ¹ì–´
    pdf_parser = subparsers.add_parser("index-pdf", help="PDF íŒŒì¼ ì§ì ‘ ì¸ë±ì‹±")
    pdf_parser.add_argument("--path", required=True, help="PDF íŒŒì¼ ê²½ë¡œ")
    pdf_parser.add_argument("--stock-code", help="ì¢…ëª©ì½”ë“œ (ë©”íƒ€ë°ì´í„°)")
    pdf_parser.add_argument("--stock-name", help="ì¢…ëª©ëª… (ë©”íƒ€ë°ì´í„°)")
    pdf_parser.add_argument("--data-type", default="report", help="ë°ì´í„° ìœ í˜• (report, news, etc)")
    
    # index-dir ëª…ë ¹ì–´
    dir_parser = subparsers.add_parser("index-dir", help="ë””ë ‰í† ë¦¬ ì¼ê´„ ì¸ë±ì‹±")
    dir_parser.add_argument("--path", required=True, help="ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    dir_parser.add_argument("--pattern", default="*.pdf", help="íŒŒì¼ íŒ¨í„´ (ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: *.pdf,*.txt)")
    dir_parser.add_argument("--stock-code", help="ì¢…ëª©ì½”ë“œ (ë©”íƒ€ë°ì´í„°)")
    dir_parser.add_argument("--stock-name", help="ì¢…ëª©ëª… (ë©”íƒ€ë°ì´í„°)")
    dir_parser.add_argument("--no-recursive", action="store_true", help="í•˜ìœ„ ë””ë ‰í† ë¦¬ ì œì™¸")
    
    # search ëª…ë ¹ì–´
    search_parser = subparsers.add_parser("search", help="ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    search_parser.add_argument("--query", required=True, help="ê²€ìƒ‰ ì¿¼ë¦¬")
    search_parser.add_argument("--k", type=int, default=5, help="ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸: 5)")
    search_parser.add_argument("--no-reranker", action="store_true", help="ë¦¬ë­ì»¤ ë¹„í™œì„±í™”")
    
    # status ëª…ë ¹ì–´
    subparsers.add_parser("status", help="ìƒíƒœ í™•ì¸")
    
    # rebuild ëª…ë ¹ì–´
    rebuild_parser = subparsers.add_parser("rebuild", help="ì„ë² ë”© ì¬êµ¬ì¶•")
    rebuild_parser.add_argument("--code", help="íŠ¹ì • ì¢…ëª©ë§Œ ì¬êµ¬ì¶•")
    
    # clear ëª…ë ¹ì–´
    subparsers.add_parser("clear", help="ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” (ì£¼ì˜!)")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # ëª…ë ¹ì–´ ì‹¤í–‰
    commands = {
        "ingest": cmd_ingest,
        "ingest-batch": cmd_ingest_batch,
        "index-pdf": cmd_index_pdf,
        "index-dir": cmd_index_dir,
        "search": cmd_search,
        "status": cmd_status,
        "rebuild": cmd_rebuild,
        "clear": cmd_clear,
    }
    
    start_time = datetime.now()
    
    try:
        result = commands[args.command](args)
        
        elapsed = datetime.now() - start_time
        print(f"\nâ±ï¸ ì‹¤í–‰ ì‹œê°„: {elapsed.total_seconds():.1f}ì´ˆ")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
