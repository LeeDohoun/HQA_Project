# íŒŒì¼: src/data_pipeline/data_ingestion.py
"""
ë°ì´í„° ìˆ˜ì§‘ â†’ ì›ë³¸ ì €ì¥ â†’ RAG ë²¡í„°í™” í†µí•© íŒŒì´í”„ë¼ì¸

íë¦„:
1. ë°ì´í„° ìˆ˜ì§‘ (í¬ë¡¤ëŸ¬, API)
2. ì›ë³¸ DB ì €ì¥ (SQLite) - ì¤‘ë³µ ì²´í¬
3. RAG ë²¡í„°í™” (ChromaDB) - ë¯¸ì²˜ë¦¬ ë°ì´í„°ë§Œ
"""

import os
from typing import List, Dict, Optional
from datetime import datetime

# ë°ì´í„° ìˆ˜ì§‘ê¸°
from .price_loader import PriceLoader
from .dart_collector import DARTCollector, Disclosure
from .news_crawler import NewsCrawler, NewsArticle
from .crawler import ReportCrawler, Report

# ì›ë³¸ ë°ì´í„° ì €ì¥ì†Œ
from src.database.raw_data_store import (
    RawDataStore,
    RawReport,
    RawNews,
    RawDisclosure,
    RawPriceData
)

# RAG ëª¨ë“ˆ
from src.rag import (
    DocumentLoader,
    VectorStoreManager
)


class DataIngestionPipeline:
    """ë°ì´í„° ìˆ˜ì§‘ â†’ ì›ë³¸ ì €ì¥ â†’ RAG ë²¡í„°í™” í†µí•© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        db_path: str = "./database/raw_data.db",
        files_dir: str = "./data/files",
        vector_persist_dir: str = "./database/chroma_db",
        collection_name: str = "stock_data",
        use_multimodal: bool = True,  # ê¸°ë³¸ê°’ True â†’ Qwen3-VL ì‚¬ìš©
        embedding_model: str = "multimodal-2b"  # 2B ë˜ëŠ” 8B
    ):
        """
        Args:
            db_path: SQLite DB ê²½ë¡œ
            files_dir: PDF ë“± íŒŒì¼ ì €ì¥ ê²½ë¡œ
            vector_persist_dir: ë²¡í„° DB ì €ì¥ ê²½ë¡œ
            collection_name: ë²¡í„° ì»¬ë ‰ì…˜ ì´ë¦„
            use_multimodal: Qwen3-VL ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ì‚¬ìš© ì—¬ë¶€
            embedding_model: ì„ë² ë”© ëª¨ë¸ ("multimodal-2b", "multimodal-8b")
        """
        print("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
        
        # 1. ë°ì´í„° ìˆ˜ì§‘ê¸°
        self.price_loader = PriceLoader()
        self.dart_collector = DARTCollector()
        self.news_crawler = NewsCrawler()
        self.report_crawler = ReportCrawler(download_dir=os.path.join(files_dir, "reports"))
        
        # 2. ì›ë³¸ ë°ì´í„° ì €ì¥ì†Œ (SQLite)
        self.raw_store = RawDataStore(db_path=db_path, files_dir=files_dir)
        
        # 3. RAG ë²¡í„° ì €ì¥ì†Œ (ChromaDB + Qwen3-VL)
        self.use_multimodal = use_multimodal
        self.vector_store = VectorStoreManager(
            persist_dir=vector_persist_dir,
            collection_name=collection_name,
            embedding_type=embedding_model if use_multimodal else "korean",
            use_multimodal=use_multimodal
        )
        
        # 4. PDF ë¡œë”
        self.doc_loader = DocumentLoader()
        
        if use_multimodal:
            print(f"ğŸ§  Qwen3-VL ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© í™œì„±í™” ({embedding_model})")
            print("   - í…ìŠ¤íŠ¸ ë°ì´í„° â†’ Qwen3-VL í…ìŠ¤íŠ¸ ì„ë² ë”©")
            print("   - ì´ë¯¸ì§€ ë°ì´í„° â†’ Qwen3-VL ì´ë¯¸ì§€ ì„ë² ë”©")
        
        print("âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ==================== ë©”ì¸ ìˆ˜ì§‘ í•¨ìˆ˜ ====================
    
    def ingest_stock_data(
        self,
        stock_code: str,
        stock_name: str,
        include_reports: bool = True,
        include_news: bool = True,
        include_dart: bool = True,
        include_price: bool = True,
        auto_embed: bool = True  # ìˆ˜ì§‘ í›„ ìë™ ì„ë² ë”©
    ) -> Dict:
        """
        íŠ¹ì • ì¢…ëª©ì˜ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ â†’ ì›ë³¸ ì €ì¥ â†’ RAG ë²¡í„°í™”
        
        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            stock_name: ì¢…ëª©ëª…
            include_reports: ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ í¬í•¨ ì—¬ë¶€
            include_news: ë‰´ìŠ¤ í¬í•¨ ì—¬ë¶€
            include_dart: DART ê³µì‹œ í¬í•¨ ì—¬ë¶€
            include_price: ì£¼ê°€ ë°ì´í„° í¬í•¨ ì—¬ë¶€
            auto_embed: ìˆ˜ì§‘ í›„ ìë™ìœ¼ë¡œ RAG ì„ë² ë”© ì—¬ë¶€
            
        Returns:
            ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“Š [{stock_name}({stock_code})] ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"{'='*60}")
        
        results = {
            "stock_code": stock_code,
            "stock_name": stock_name,
            "timestamp": datetime.now().isoformat(),
            "collected": {"reports": 0, "news": 0, "disclosures": 0, "price": 0},
            "new_items": {"reports": 0, "news": 0, "disclosures": 0},
            "embedded": {"reports": 0, "news": 0, "disclosures": 0, "price": 0}
        }
        
        # 1. ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        if include_price:
            results["collected"]["price"] = self._collect_price(stock_code, stock_name)
        
        # 2. ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ë° ì €ì¥
        if include_reports:
            collected, new = self._collect_reports(stock_code, stock_name)
            results["collected"]["reports"] = collected
            results["new_items"]["reports"] = new
        
        # 3. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì €ì¥
        if include_news:
            collected, new = self._collect_news(stock_code, stock_name)
            results["collected"]["news"] = collected
            results["new_items"]["news"] = new
        
        # 4. DART ê³µì‹œ ìˆ˜ì§‘ ë° ì €ì¥
        if include_dart:
            collected, new = self._collect_disclosures(stock_code, stock_name)
            results["collected"]["disclosures"] = collected
            results["new_items"]["disclosures"] = new
        
        # 5. ë¯¸ì„ë² ë”© ë°ì´í„° â†’ RAG ë²¡í„°í™”
        if auto_embed:
            print(f"\nğŸ”„ RAG ë²¡í„°í™” ì‹œì‘...")
            embedded = self.embed_pending_data(stock_code)
            results["embedded"] = embedded
        
        # ê²°ê³¼ ìš”ì•½
        self._print_summary(results)
        
        return results
    
    # ==================== ê°œë³„ ìˆ˜ì§‘ í•¨ìˆ˜ ====================
    
    def _collect_price(self, stock_code: str, stock_name: str) -> int:
        """ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"""
        print(f"\nğŸ“ˆ [1/4] ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘...")
        
        try:
            df = self.price_loader.get_stock_data(stock_code, days=300)
            
            if len(df) < 150:
                print(f"   âš ï¸ ë°ì´í„° ë¶€ì¡± ({len(df)}ì¼)")
                return 0
            
            # 150ì¼ ì´í‰ì„  ê³„ì‚°
            df['MA150'] = df['Close'].rolling(window=150).mean()
            
            # ìµœê·¼ ë°ì´í„°ë§Œ ì €ì¥ (ìµœê·¼ 30ì¼)
            recent_df = df.tail(30)
            count = 0
            
            for date, row in recent_df.iterrows():
                is_bullish = row['Close'] > row['MA150'] if row['MA150'] else None
                
                price_data = RawPriceData(
                    stock_code=stock_code,
                    stock_name=stock_name,
                    date=date.strftime("%Y-%m-%d"),
                    open_price=row['Open'],
                    high_price=row['High'],
                    low_price=row['Low'],
                    close_price=row['Close'],
                    volume=int(row['Volume']),
                    ma150=row['MA150'] if row['MA150'] else None,
                    is_bullish=is_bullish
                )
                self.raw_store.save_price_data(price_data)
                count += 1
            
            print(f"   âœ… {count}ì¼ì¹˜ ì£¼ê°€ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            return count
            
        except Exception as e:
            print(f"   âŒ ì£¼ê°€ ë°ì´í„° ì˜¤ë¥˜: {e}")
            return 0
    
    def _collect_reports(self, stock_code: str, stock_name: str) -> tuple:
        """ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ë° ì €ì¥"""
        print(f"\nğŸ“‘ [2/4] ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ ìˆ˜ì§‘...")
        
        try:
            reports = self.report_crawler.fetch_and_download(stock_code, max_count=5)
            new_count = 0
            
            for report in reports:
                # ì¤‘ë³µ ì²´í¬
                if self.raw_store.is_report_exists(report['link']):
                    continue
                
                # ì›ë³¸ ì €ì¥
                raw_report = RawReport(
                    stock_code=stock_code,
                    stock_name=stock_name,
                    title=report['title'],
                    broker=report['broker'],
                    report_date=report['date'],
                    link=report['link'],
                    pdf_path=report.get('local_path')
                )
                self.raw_store.save_report(raw_report)
                new_count += 1
            
            print(f"   âœ… {len(reports)}ê°œ ìˆ˜ì§‘, {new_count}ê°œ ì‹ ê·œ ì €ì¥")
            return len(reports), new_count
            
        except Exception as e:
            print(f"   âŒ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return 0, 0
    
    def _collect_news(self, stock_code: str, stock_name: str) -> tuple:
        """ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì €ì¥"""
        print(f"\nğŸ“° [3/4] ë‰´ìŠ¤ ìˆ˜ì§‘...")
        
        try:
            articles = self.news_crawler.fetch_stock_news(stock_code, stock_name, max_count=10)
            new_count = 0
            
            for article in articles:
                # ì¤‘ë³µ ì²´í¬
                if self.raw_store.is_news_exists(article.url):
                    continue
                
                # ì›ë³¸ ì €ì¥
                raw_news = RawNews(
                    stock_code=stock_code,
                    stock_name=stock_name,
                    title=article.title,
                    summary=article.summary,
                    source=article.source,
                    url=article.url,
                    published_at=article.published_at
                )
                self.raw_store.save_news(raw_news)
                new_count += 1
            
            print(f"   âœ… {len(articles)}ê°œ ìˆ˜ì§‘, {new_count}ê°œ ì‹ ê·œ ì €ì¥")
            return len(articles), new_count
            
        except Exception as e:
            print(f"   âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return 0, 0
    
    def _collect_disclosures(self, stock_code: str, stock_name: str) -> tuple:
        """DART ê³µì‹œ ìˆ˜ì§‘ ë° ì €ì¥"""
        print(f"\nğŸ“‹ [4/4] DART ê³µì‹œ ìˆ˜ì§‘...")
        
        if not self.dart_collector.api_key:
            print("   âš ï¸ DART API í‚¤ ë¯¸ì„¤ì • - ê±´ë„ˆëœ€")
            return 0, 0
        
        try:
            disclosures = self.dart_collector.fetch_disclosures(
                stock_code=stock_code,
                max_count=10
            )
            new_count = 0
            
            for disc in disclosures:
                # ì¤‘ë³µ ì²´í¬ (receipt_no ê¸°ì¤€)
                existing = self.raw_store.get_disclosures(stock_code)
                if any(d.receipt_no == disc.rcept_no for d in existing):
                    continue
                
                # ì›ë³¸ ì €ì¥
                raw_disc = RawDisclosure(
                    stock_code=stock_code,
                    stock_name=stock_name,
                    corp_code=disc.corp_code,
                    report_name=disc.report_nm,
                    receipt_no=disc.rcept_no,
                    receipt_date=disc.rcept_dt,
                    submitter=disc.flr_nm,
                    url=disc.url
                )
                self.raw_store.save_disclosure(raw_disc)
                new_count += 1
            
            print(f"   âœ… {len(disclosures)}ê°œ ìˆ˜ì§‘, {new_count}ê°œ ì‹ ê·œ ì €ì¥")
            return len(disclosures), new_count
            
        except Exception as e:
            print(f"   âŒ ê³µì‹œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return 0, 0
    
    # ==================== RAG ì„ë² ë”© ====================
    
    def embed_pending_data(self, stock_code: Optional[str] = None) -> Dict:
        """
        ë¯¸ì„ë² ë”© ë°ì´í„°ë¥¼ RAG ë²¡í„°í™” (Qwen3-VL ì‚¬ìš©)
        
        ì²˜ë¦¬ ë°©ì‹:
        - ë¦¬í¬íŠ¸ PDF: ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ Qwen3-VL ì´ë¯¸ì§€ ì„ë² ë”©
        - ë‰´ìŠ¤/ê³µì‹œ: Qwen3-VL í…ìŠ¤íŠ¸ ì„ë² ë”©
        - ì£¼ê°€ ë°ì´í„°: ì„ë² ë”© ì œì™¸ (êµ¬ì¡°í™” ë°ì´í„°ë¡œ ë³„ë„ ë¶„ì„)
        
        Args:
            stock_code: íŠ¹ì • ì¢…ëª©ë§Œ ì²˜ë¦¬ (Noneì´ë©´ ì „ì²´)
            
        Returns:
            ì„ë² ë”© ê²°ê³¼
        """
        results = {"reports": 0, "news": 0, "disclosures": 0}
        
        print(f"\n{'='*50}")
        print(f"ğŸ§  Qwen3-VL ì„ë² ë”© ì²˜ë¦¬ ì‹œì‘")
        print(f"{'='*50}")
        
        # 1. ë¯¸ì„ë² ë”© ë¦¬í¬íŠ¸ ì²˜ë¦¬ (PDF â†’ ì´ë¯¸ì§€ ì„ë² ë”©)
        reports = self.raw_store.get_reports(stock_code, not_embedded_only=True)
        print(f"\nğŸ“‘ [1/3] ë¦¬í¬íŠ¸ ì²˜ë¦¬ ({len(reports)}ê±´) - ì´ë¯¸ì§€ ì„ë² ë”©")
        
        for report in reports:
            try:
                metadata = {
                    "stock_code": report.stock_code,
                    "stock_name": report.stock_name,
                    "data_type": "report",
                    "broker": report.broker,
                    "report_date": report.report_date,
                    "source_id": report.id
                }
                
                # PDF â†’ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ Qwen3-VL ì´ë¯¸ì§€ ì„ë² ë”©
                if report.pdf_path and os.path.exists(report.pdf_path):
                    print(f"   ğŸ–¼ï¸ {report.title[:30]}...")
                    processed = self.doc_loader.load(report.pdf_path)
                    self.vector_store.add_document(processed, doc_metadata=metadata)
                else:
                    # PDF ì—†ìœ¼ë©´ ë©”íƒ€ì •ë³´ë§Œ í…ìŠ¤íŠ¸ë¡œ ì €ì¥
                    print(f"   ğŸ“ {report.title[:30]}... (PDF ì—†ìŒ)")
                    text = f"[ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸] {report.title}\nì¦ê¶Œì‚¬: {report.broker}\në‚ ì§œ: {report.report_date}"
                    self.vector_store.add_texts([text], metadatas=[metadata])
                
                self.raw_store.mark_as_embedded("reports", [report.id])
                results["reports"] += 1
            except Exception as e:
                print(f"   âš ï¸ ë¦¬í¬íŠ¸ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        
        # 2. ë¯¸ì„ë² ë”© ë‰´ìŠ¤ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš© â†’ Qwen3-VL í…ìŠ¤íŠ¸ ì„ë² ë”©)
        news_list = self.raw_store.get_news(stock_code, not_embedded_only=True)
        print(f"\nğŸ“° [2/3] ë‰´ìŠ¤ ì²˜ë¦¬ ({len(news_list)}ê±´) - í…ìŠ¤íŠ¸ ì „ìš©")
        
        news_ids = []
        for news in news_list:
            try:
                metadata = {
                    "stock_code": news.stock_code,
                    "stock_name": news.stock_name,
                    "data_type": "news",
                    "source": news.source,
                    "url": news.url,
                    "published_at": news.published_at,
                    "source_id": news.id
                }
                
                text = f"[ë‰´ìŠ¤] {news.title}\n{news.summary}"
                if news.content:
                    text += f"\n\n{news.content}"
                
                self.vector_store.add_texts([text], metadatas=[metadata])
                news_ids.append(news.id)
            except Exception as e:
                print(f"   âš ï¸ ë‰´ìŠ¤ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        
        if news_ids:
            self.raw_store.mark_as_embedded("news", news_ids)
            results["news"] = len(news_ids)
        
        # 3. ë¯¸ì„ë² ë”© ê³µì‹œ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš© â†’ Qwen3-VL í…ìŠ¤íŠ¸ ì„ë² ë”©)
        disclosures = self.raw_store.get_disclosures(stock_code, not_embedded_only=True)
        print(f"\nğŸ“‹ [3/3] ê³µì‹œ ì²˜ë¦¬ ({len(disclosures)}ê±´) - í…ìŠ¤íŠ¸ ì „ìš©")
        
        disc_ids = []
        for disc in disclosures:
            try:
                metadata = {
                    "stock_code": disc.stock_code,
                    "stock_name": disc.stock_name,
                    "data_type": "disclosure",
                    "report_name": disc.report_name,
                    "receipt_date": disc.receipt_date,
                    "url": disc.url,
                    "source_id": disc.id
                }
                
                text = f"[ê³µì‹œ] {disc.report_name}\nì œì¶œì: {disc.submitter}\nì ‘ìˆ˜ì¼: {disc.receipt_date}"
                if disc.content:
                    text += f"\n\n{disc.content}"
                
                self.vector_store.add_texts([text], metadatas=[metadata])
                disc_ids.append(disc.id)
            except Exception as e:
                print(f"   âš ï¸ ê³µì‹œ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        
        if disc_ids:
            self.raw_store.mark_as_embedded("disclosures", disc_ids)
            results["disclosures"] = len(disc_ids)
        
        # ì£¼ê°€ ë°ì´í„°ëŠ” ì„ë² ë”© ì œì™¸ (êµ¬ì¡°í™” ë°ì´í„°ë¡œ ë³„ë„ ë¶„ì„)
        print(f"\nğŸ’° ì£¼ê°€ ë°ì´í„°: ì„ë² ë”© ì œì™¸ (SQLiteì—ì„œ ì§ì ‘ ì¡°íšŒ)")
        
        print(f"\n{'='*50}")
        print(f"âœ… ì„ë² ë”© ì™„ë£Œ (Qwen3-VL ëª¨ë¸ ì‚¬ìš©)")
        print(f"   - ë¦¬í¬íŠ¸: {results['reports']}ê±´ (PDF â†’ ì´ë¯¸ì§€)")
        print(f"   - ë‰´ìŠ¤: {results['news']}ê±´ (í…ìŠ¤íŠ¸ ì „ìš©)")
        print(f"   - ê³µì‹œ: {results['disclosures']}ê±´ (í…ìŠ¤íŠ¸ ì „ìš©)")
        print(f"{'='*50}")
        
        return results
    
    # ==================== ìœ í‹¸ë¦¬í‹° ====================
    
    def search(self, query: str, k: int = 5) -> List:
        """RAG ê²€ìƒ‰"""
        return self.vector_store.search_text(query, k=k)
    
    def get_stats(self) -> Dict:
        """ì „ì²´ í†µê³„"""
        raw_stats = self.raw_store.get_stats()
        vector_stats = self.vector_store.get_stats()
        
        return {
            "raw_data": raw_stats,
            "vector_store": vector_stats
        }
    
    def _print_summary(self, results: Dict):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š [{results['stock_name']}] ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"ğŸ“¥ ìˆ˜ì§‘: ë¦¬í¬íŠ¸ {results['collected']['reports']}, "
              f"ë‰´ìŠ¤ {results['collected']['news']}, "
              f"ê³µì‹œ {results['collected']['disclosures']}, "
              f"ì£¼ê°€ {results['collected']['price']}ì¼")
        print(f"ğŸ†• ì‹ ê·œ: ë¦¬í¬íŠ¸ {results['new_items']['reports']}, "
              f"ë‰´ìŠ¤ {results['new_items']['news']}, "
              f"ê³µì‹œ {results['new_items']['disclosures']}")
        print(f"ğŸ”— RAG: ë¦¬í¬íŠ¸ {results['embedded']['reports']}, "
              f"ë‰´ìŠ¤ {results['embedded']['news']}, "
              f"ê³µì‹œ {results['embedded']['disclosures']}, "
              f"ì£¼ê°€ {results['embedded']['price']}")
        print(f"{'='*60}")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    pipeline = DataIngestionPipeline()
    
    # ì‚¼ì„±ì „ì ë°ì´í„° ìˆ˜ì§‘
    results = pipeline.ingest_stock_data(
        stock_code="005930",
        stock_name="ì‚¼ì„±ì „ì",
        include_dart=False  # API í‚¤ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
    )
    
    # í†µê³„ í™•ì¸
    print("\nğŸ“Š ì €ì¥ì†Œ í†µê³„:")
    stats = pipeline.get_stats()
    print(f"   ì›ë³¸ DB: {stats['raw_data']['db_size_mb']}MB")
    print(f"   íŒŒì¼: {stats['raw_data']['files_size_mb']}MB")
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: 'ì‚¼ì„±ì „ì ì‹¤ì '")
    docs = pipeline.search("ì‚¼ì„±ì „ì ì‹¤ì ", k=3)
    for doc in docs:
        print(f"- {doc.page_content[:100]}...")
